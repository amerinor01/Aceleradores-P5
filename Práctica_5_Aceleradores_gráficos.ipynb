{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Práctica 5 Aceleradores gráficos",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3T0jThVJPHh8Cs+oOsbD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amerinor01/Aceleradores-P5/blob/master/Pr%C3%A1ctica_5_Aceleradores_gr%C3%A1ficos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbWwTWRixHES"
      },
      "source": [
        "# Práctica 5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0De8pACmxLtT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZmTQxCmxPWU"
      },
      "source": [
        "files = ['double.txt', 'float.txt']\n",
        "seq_files = ['double_seq.txt', 'float_seq.txt']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t539AWxmxMl0"
      },
      "source": [
        "def parserToJson(data):\n",
        "  result = {\n",
        "      #'Iteration': int(data[0].split(' ')[1]),\n",
        "      'Option': int(data[0].split(' ')[3]),\n",
        "      'Matrix Size': int(data[0].split(' ')[5]),\n",
        "      'Kernel Time': float(data[1].split(' ')[6]),\n",
        "      'Gb Kernel': float(data[1].split(' ')[8]),\n",
        "      'Total Time': float(data[2].split(' ')[6]),\n",
        "      'Gb Total': float(data[2].split(' ')[7]),\n",
        "      'Warps Launched': float(data[3].split(' ')[3]),\n",
        "      'Local Store': float(data[4].split(' ')[3]),\n",
        "      'Global Store': float(data[5].split(' ')[3]),\n",
        "      'Local Load': float(data[6].split(' ')[3]),\n",
        "      'Global Load': float(data[7].split(' ')[3]),\n",
        "      'Shared Load': float(data[8].split(' ')[3]),\n",
        "      'Shared Store': float(data[9].split(' ')[3]),\n",
        "      'shared_load_transactions_per_request': float(data[10].split(' ')[9]),\n",
        "      'shared_store_transactions_per_request': float(data[11].split(' ')[9]),\n",
        "      'local_load_transactions_per_request': float(data[12].split(' ')[9]),\n",
        "      'local_store_transactions_per_request': float(data[13].split(' ')[9]),\n",
        "      'shared_store_transactions': float(data[14].split(' ')[6]),\n",
        "      'shared_load_transactions': float(data[15].split(' ')[6]),\n",
        "      'local_load_transactions': float(data[16].split(' ')[6]),\n",
        "      'local_store_transactions': float(data[17].split(' ')[6]),\n",
        "      'gld_transactions': float(data[18].split(' ')[6]),\n",
        "      'gsd_transactions': float(data[19].split(' ')[6]),\n",
        "      \n",
        "      \n",
        "\n",
        "  }\n",
        "  return result\n",
        "def parserSeqToJson(data):\n",
        "  result = {\n",
        "      #'Iteration': int(data[0].split(' ')[1]),\n",
        "      'Option': int(data[0].split(' ')[3]),\n",
        "      'Matrix Size': int(data[0].split(' ')[5]),\n",
        "      'Kernel Time': float(data[1].split(' ')[6]),\n",
        "      'Gb Kernel': float(data[1].split(' ')[8]),\n",
        "      'Total Time': float(data[2].split(' ')[6]),\n",
        "      'Gb Total': float(data[2].split(' ')[7]),\n",
        "\n",
        "      \n",
        "      \n",
        "\n",
        "  }\n",
        "  return result\n",
        "\n",
        "\n",
        "def getData(filename):\n",
        "  data = []\n",
        "  lista = []\n",
        "  with open(filename) as f:\n",
        "    content = f.read().splitlines()\n",
        "\n",
        "  \n",
        "  for s in content:\n",
        "    \n",
        "    if s is not '':\n",
        "      lista.append(s)\n",
        "    else:\n",
        "      data.append(parserToJson(lista))\n",
        "      lista.clear()\n",
        "  \n",
        "  \n",
        "  return data\n",
        "\n",
        "\n",
        "def getSeqData(filename):\n",
        "  data = []\n",
        "  lista = []\n",
        "  with open(filename) as f:\n",
        "    content = f.read().splitlines()\n",
        "\n",
        "  \n",
        "  for s in content:\n",
        "    \n",
        "    if s is not '':\n",
        "      lista.append(s)\n",
        "    else:\n",
        "      data.append(parserSeqToJson(lista))\n",
        "      lista.clear()\n",
        "  \n",
        "  \n",
        "  return data\n",
        "\n",
        "def get_dataframe(programa):\n",
        "\n",
        "  x = getData(programa)\n",
        "  x[0]\n",
        "  df = pd.DataFrame(x[0],[0])\n",
        "\n",
        "  for i in range(1,len(x)):\n",
        "    df = df.append(x[i], ignore_index=True)\n",
        "    \n",
        "  t = df#.get(['Option', 'Matrix Size','Kernel Time','Gb Kernel' ,'Total Time', 'Gb Total'])\n",
        "  p = t.groupby(by=['Option','Matrix Size']).mean()\n",
        "  \n",
        "  return p\n",
        "\n",
        "\n",
        "def get_seqDataframe(programa):\n",
        "\n",
        "  x = getSeqData(programa)\n",
        "  x[0]\n",
        "  df = pd.DataFrame(x[0],[0])\n",
        "\n",
        "  for i in range(1,len(x)):\n",
        "    df = df.append(x[i], ignore_index=True)\n",
        "    \n",
        "  t = df#.get(['Option', 'Matrix Size','Kernel Time','Gb Kernel' ,'Total Time', 'Gb Total'])\n",
        "  p = t.groupby(by=['Matrix Size']).mean()\n",
        "  \n",
        "  return p\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E4IreiSxPL_"
      },
      "source": [
        "dfs = []\n",
        "dfs_seq = []\n",
        "for x in files:\n",
        "  dfs.append(get_dataframe(x))\n",
        "\n",
        "for x in seq_files:\n",
        "  dfs_seq.append(get_seqDataframe(x))\n",
        "\n",
        "v = 0\n",
        "with pd.ExcelWriter('output.xlsx') as writer:  \n",
        "    for df in dfs:\n",
        "      df.to_excel(writer, sheet_name='Program' + str(v))\n",
        "      v = v + 1\n",
        "    for df in dfs_seq:\n",
        "      df.to_excel(writer, sheet_name='Program' + str(v))\n",
        "      v = v + 1\n",
        "\n",
        "#tmp = tmp.loc[tmp.loc['Matrix Size'] == 1024]\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER08kRlrxO3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}